{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 84797,
          "databundleVersionId": 9530234,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a0551371bba4bf5b099326a46fa8059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c813c30e04f4ca6ba7a4a656e56a5b7",
              "IPY_MODEL_efc0b1a765eb48ec92be78e140ec21bb",
              "IPY_MODEL_83aa103eba9645daafdcef0b54223e89"
            ],
            "layout": "IPY_MODEL_f4340ef21cd04664965add3d0ec3aa45"
          }
        },
        "1c813c30e04f4ca6ba7a4a656e56a5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f379cb74a94046f496f0de2d03ee933f",
            "placeholder": "​",
            "style": "IPY_MODEL_c262e63427c34f07a19ad37c686a184e",
            "value": "model.safetensors: 100%"
          }
        },
        "efc0b1a765eb48ec92be78e140ec21bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52820c343d3d44ccacbbed70e7d5f53b",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a0352abbff747829537cab70880be9f",
            "value": 346284714
          }
        },
        "83aa103eba9645daafdcef0b54223e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff6ca98e665413994e485cb814a199a",
            "placeholder": "​",
            "style": "IPY_MODEL_ec403adbe96346a4891d6b5717465918",
            "value": " 346M/346M [00:02&lt;00:00, 146MB/s]"
          }
        },
        "f4340ef21cd04664965add3d0ec3aa45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f379cb74a94046f496f0de2d03ee933f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c262e63427c34f07a19ad37c686a184e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52820c343d3d44ccacbbed70e7d5f53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0352abbff747829537cab70880be9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ff6ca98e665413994e485cb814a199a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec403adbe96346a4891d6b5717465918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'emo-map-challenge:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F84797%2F9530234%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240916%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240916T081747Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D511f54dcacc0803da7ba8fbcb9f37755157c416020ea2b1350130af4e34d493267520d7d8f78a24cf0854073af4733eca3155b33ddc7849c11cfb81941642a79c83e88440800f61268827298f8662632fe23591261335cd7f98e07cc75d4118eeb6162c7bd1d9d3d3047c8e4e0ab1365acbbee30052a8c25a792637fb99eedcf9a4f8c00bc7b87675811513627d57797a3f9c94454f0a10b55567e098526e0ae7c619af622b67375ac56d8757449fe60cee7a970464908b8c37906aa45323d02a06f9da1999cf9c3e1e4c167714c61733ebbc783145c086036cd44d0468a77150bda67d8415deb4b675cf4fe3d9b900d9d2b46225c3723b97492bd82d7496ca0'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ErF2yZqk6Amq",
        "outputId": "0316ae1a-859f-4fd1-ebad-d5f371fe9b1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading emo-map-challenge, 21203873 bytes compressed\n",
            "[==================================================] 21203873 bytes downloaded\n",
            "Downloaded and uncompressed: emo-map-challenge\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-16T08:15:44.820765Z",
          "iopub.execute_input": "2024-09-16T08:15:44.821175Z",
          "iopub.status.idle": "2024-09-16T08:15:45.25117Z",
          "shell.execute_reply.started": "2024-09-16T08:15:44.821132Z",
          "shell.execute_reply": "2024-09-16T08:15:45.249875Z"
        },
        "trusted": true,
        "id": "QwSa9F1F6Amu",
        "outputId": "213e1628-cc6b-4a93-aa4f-4f72a5a711d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/emo-map-challenge/train_dataset.csv\n",
            "/kaggle/input/emo-map-challenge/sample_submission.csv\n",
            "/kaggle/input/emo-map-challenge/test_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision timm\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T08:16:03.48909Z",
          "iopub.execute_input": "2024-09-16T08:16:03.490245Z",
          "iopub.status.idle": "2024-09-16T08:16:18.250622Z",
          "shell.execute_reply.started": "2024-09-16T08:16:03.490169Z",
          "shell.execute_reply": "2024-09-16T08:16:18.24917Z"
        },
        "trusted": true,
        "id": "Grz-ewIB6Amv",
        "outputId": "5620ae64-de5a-4943-8938-b96f62b08247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Collecting timm\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m576.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.6)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "Successfully installed timm-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_link='/kaggle/input/emo-map-challenge/train_dataset.csv'\n",
        "train_df=pd.read_csv(train_link)\n",
        "train_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T08:16:18.252913Z",
          "iopub.execute_input": "2024-09-16T08:16:18.253339Z",
          "iopub.status.idle": "2024-09-16T08:16:19.163325Z",
          "shell.execute_reply.started": "2024-09-16T08:16:18.253297Z",
          "shell.execute_reply": "2024-09-16T08:16:19.162222Z"
        },
        "trusted": true,
        "id": "pEbYsDiX6Amw",
        "outputId": "1fa35014-a6eb-4468-ed9b-d29d2a3d3f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                             pixels  emotion\n",
              "0        1  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...        0\n",
              "1        2  151 150 147 155 148 133 111 140 170 174 182 15...        0\n",
              "2        3  231 212 156 164 174 138 161 173 182 200 106 38...        2\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...        4\n",
              "4        5  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...        6\n",
              "...    ...                                                ...      ...\n",
              "4995  4996  22 24 23 23 25 24 23 20 18 13 6 2 0 1 7 22 32 ...        3\n",
              "4996  4997  73 85 87 87 74 118 120 132 134 127 133 118 105...        3\n",
              "4997  4998  253 253 254 254 254 254 250 219 166 141 109 70...        6\n",
              "4998  4999  78 84 77 95 90 85 72 75 79 84 86 82 88 102 110...        6\n",
              "4999  5000  98 100 102 104 107 109 111 119 126 130 53 5 12...        3\n",
              "\n",
              "[5000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc5e3c4e-39fb-4749-a2f2-d4f289a258ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>pixels</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>4996</td>\n",
              "      <td>22 24 23 23 25 24 23 20 18 13 6 2 0 1 7 22 32 ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>4997</td>\n",
              "      <td>73 85 87 87 74 118 120 132 134 127 133 118 105...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>4998</td>\n",
              "      <td>253 253 254 254 254 254 250 219 166 141 109 70...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>4999</td>\n",
              "      <td>78 84 77 95 90 85 72 75 79 84 86 82 88 102 110...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>5000</td>\n",
              "      <td>98 100 102 104 107 109 111 119 126 130 53 5 12...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc5e3c4e-39fb-4749-a2f2-d4f289a258ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc5e3c4e-39fb-4749-a2f2-d4f289a258ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc5e3c4e-39fb-4749-a2f2-d4f289a258ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc2fa0dd-7d81-409c-bbbc-38c3a223d1d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc2fa0dd-7d81-409c-bbbc-38c3a223d1d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc2fa0dd-7d81-409c-bbbc-38c3a223d1d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d7f4d4c8-e765-4aa1-85c0-6655666c26a7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d7f4d4c8-e765-4aa1-85c0-6655666c26a7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1443,\n        \"min\": 1,\n        \"max\": 5000,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          1502,\n          2587,\n          2654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4958,\n        \"samples\": [\n          \"232 230 240 115 37 37 32 39 36 31 33 29 24 36 96 162 177 192 195 197 199 198 199 199 201 201 200 198 197 195 182 166 158 62 24 30 33 30 32 27 26 27 32 42 52 178 238 230 230 229 234 113 28 37 48 36 33 36 32 24 68 122 162 180 186 194 199 202 203 202 200 201 203 203 202 202 198 196 192 172 168 110 18 29 31 26 27 31 31 32 27 39 53 143 234 229 228 228 226 215 66 56 45 34 35 30 29 55 147 170 175 186 192 197 202 204 204 203 203 203 203 203 201 201 197 194 192 180 165 156 65 19 31 35 33 43 39 40 37 31 43 109 216 230 226 223 223 220 77 44 35 35 22 43 96 141 167 175 183 188 193 199 204 205 204 205 205 204 202 201 200 200 196 193 192 181 170 166 154 58 19 32 32 27 34 37 53 41 28 75 208 229 225 222 223 215 74 36 31 27 24 90 156 166 178 186 188 191 196 201 204 204 205 206 205 203 202 200 201 200 196 193 188 180 174 170 165 141 38 20 31 29 25 34 40 54 25 88 207 226 224 224 225 221 75 22 26 31 60 144 167 178 188 191 190 197 202 203 205 207 208 208 207 205 202 198 199 199 196 191 186 179 174 170 166 172 132 30 20 34 39 31 32 49 28 92 225 223 221 221 220 225 69 14 34 35 75 168 176 186 189 190 192 199 204 205 206 208 208 208 207 205 203 201 200 201 198 194 188 182 175 170 175 177 170 128 49 22 32 37 28 35 17 74 223 221 219 219 219 221 60 20 47 39 102 180 183 189 190 191 195 198 205 206 206 206 206 205 206 205 202 201 202 200 197 192 185 181 178 180 186 182 173 167 153 64 23 35 37 36 16 62 223 218 218 216 220 210 43 26 43 67 124 177 187 192 193 193 195 198 204 205 205 205 204 202 200 200 198 199 199 194 190 185 178 176 178 181 188 186 184 177 171 116 35 30 36 50 21 77 226 216 216 214 217 209 46 34 68 101 156 182 189 193 194 194 197 198 201 204 204 203 204 201 198 194 193 196 195 188 182 176 173 175 177 180 188 188 190 188 178 159 79 36 27 37 42 124 227 213 214 213 211 214 66 29 86 157 176 192 192 195 196 199 201 199 199 200 202 201 202 203 200 193 190 194 195 190 181 175 172 173 178 185 195 195 195 195 190 178 145 83 47 19 21 118 220 214 212 209 209 215 89 32 62 150 186 195 196 199 202 205 207 206 203 201 199 198 198 203 201 196 194 196 197 190 183 178 181 184 188 197 205 205 202 200 194 191 178 138 78 24 19 101 218 211 210 206 202 214 153 28 77 160 195 199 200 204 207 205 198 195 194 197 203 201 196 198 202 200 199 198 192 186 184 188 199 196 192 193 200 206 209 207 201 196 195 162 74 28 45 135 219 209 209 209 206 217 164 23 81 188 194 202 207 197 180 163 144 131 138 136 141 164 186 195 199 201 201 199 190 184 177 158 140 137 137 132 148 166 182 199 207 198 192 178 96 26 36 180 214 208 207 207 203 211 172 21 55 186 200 206 196 173 172 183 188 186 184 180 171 151 151 192 199 197 194 196 192 183 146 150 169 176 180 182 184 179 169 173 196 202 196 189 127 21 82 213 204 207 206 204 194 187 160 29 111 203 201 205 193 201 202 191 179 171 169 164 179 196 182 186 198 201 195 201 199 183 176 186 162 155 164 165 175 187 196 194 191 202 197 191 142 37 137 194 199 204 205 199 182 139 63 54 153 193 201 202 199 182 154 141 143 143 143 125 123 165 185 176 188 201 201 208 201 176 179 155 120 134 142 144 141 140 155 183 197 196 197 191 138 32 112 161 181 200 201 199 166 97 42 85 167 187 199 194 179 143 116 112 90 67 69 115 147 160 174 168 180 200 202 215 197 171 173 154 150 98 62 60 97 116 117 149 184 192 197 194 128 50 176 168 171 200 200 199 168 79 65 94 194 183 196 187 172 155 105 138 64 22 49 121 145 127 184 166 183 208 203 212 195 171 180 118 155 103 44 25 90 139 114 162 177 191 193 195 122 45 191 162 176 201 199 190 174 100 123 78 186 185 196 189 181 176 165 147 127 100 107 140 157 170 184 178 189 205 207 210 201 179 180 171 157 137 113 117 138 153 168 177 185 188 190 191 126 52 148 166 189 197 199 187 171 146 151 123 180 183 191 194 195 187 183 168 163 158 144 152 166 173 185 184 184 194 199 208 202 182 177 165 162 147 145 159 165 172 177 187 195 189 187 185 181 190 193 179 198 196 194 194 192 175 193 162 167 184 183 197 202 197 188 185 185 175 166 178 180 188 193 186 185 191 193 205 200 179 182 176 169 166 159 169 171 169 181 195 196 191 183 189 171 169 201 194 194 194 193 193 188 186 202 149 160 183 177 191 202 204 204 205 199 186 183 184 192 199 192 190 187 189 194 208 200 177 175 187 184 174 171 176 181 183 197 201 199 191 175 192 168 155 208 189 193 193 192 191 189 186 198 161 175 182 174 188 192 198 203 194 189 185 187 190 198 195 189 191 190 189 193 204 203 182 172 185 192 185 182 186 191 197 204 200 202 193 175 191 189 167 202 188 193 192 190 189 190 188 195 195 186 185 178 184 190 192 199 199 197 195 194 198 198 191 188 189 193 195 195 203 203 187 174 182 191 194 191 193 197 198 199 199 198 192 180 194 197 199 198 188 190 190 188 188 188 187 191 204 197 183 180 184 192 199 198 200 201 199 202 202 193 183 179 183 198 205 202 207 203 195 171 180 191 193 192 190 194 189 190 194 195 189 178 190 201 204 193 187 188 188 186 186 186 185 189 201 192 176 175 183 190 195 196 196 200 208 208 198 185 176 173 188 201 206 207 201 192 193 180 176 191 193 195 196 190 188 188 193 196 189 175 187 189 200 192 185 186 186 184 184 184 184 183 198 189 165 172 179 184 192 191 194 207 212 204 191 182 168 174 190 187 195 189 179 168 173 184 170 186 193 189 196 196 193 195 196 197 186 175 182 193 200 184 184 184 184 183 183 183 183 183 177 164 172 169 177 181 187 192 204 212 213 196 185 177 170 176 179 135 141 163 143 116 158 164 170 184 189 194 197 199 196 197 195 195 182 177 172 188 185 182 183 183 183 182 182 182 182 183 175 131 154 174 178 179 184 198 208 207 208 194 182 175 192 183 157 80 71 173 101 54 125 157 174 182 185 192 199 195 195 193 191 191 181 178 138 158 185 181 182 182 182 179 179 179 179 178 190 136 138 174 178 180 185 194 207 207 202 194 179 193 198 188 178 157 143 166 146 139 151 166 177 185 186 185 190 191 192 191 193 185 177 189 158 128 185 178 179 179 179 178 178 178 177 181 163 151 172 167 182 179 183 190 200 207 203 188 188 208 200 189 188 201 196 157 173 181 187 183 186 192 190 186 184 187 188 193 190 182 179 177 147 166 180 178 178 178 178 177 177 177 176 180 156 128 159 173 184 180 180 186 192 201 204 192 199 207 201 198 193 204 199 163 177 188 186 194 196 193 190 190 181 181 184 190 187 180 180 172 134 164 179 177 177 177 177 175 175 175 175 176 190 136 121 178 184 184 181 180 182 190 194 195 203 203 199 196 206 213 202 176 190 207 198 190 188 193 191 186 182 178 182 186 185 180 182 182 148 111 172 176 175 175 175 173 173 173 173 173 183 141 149 179 184 189 182 179 179 178 178 192 200 199 203 200 186 172 165 167 166 165 178 191 192 187 187 184 179 177 179 183 185 186 183 188 168 126 173 173 173 173 173 172 172 172 172 172 167 138 137 166 176 185 183 181 179 173 175 187 195 200 184 164 157 147 136 131 128 125 142 151 168 181 179 177 177 178 183 185 185 185 183 171 141 137 169 173 172 172 172 171 171 171 171 170 175 180 127 131 172 173 185 185 183 178 182 183 166 134 131 140 136 108 110 121 100 93 109 110 102 121 159 176 185 191 192 188 186 180 175 173 176 135 121 171 171 171 171 169 169 169 169 168 172 189 156 111 127 176 180 190 189 189 191 187 190 166 137 129 136 169 144 94 113 129 113 108 136 168 175 184 197 195 193 191 182 173 166 160 188 175 117 162 171 169 169 168 168 168 168 168 168 171 142 111 72 119 185 190 195 196 193 187 205 213 198 158 141 166 164 135 126 118 114 155 197 187 183 192 197 193 194 189 167 171 145 95 143 160 134 168 168 168 168 166 166 166 166 166 166 165 137 91 62 60 121 179 194 198 191 191 201 195 209 201 153 123 115 120 116 118 157 194 186 174 189 192 189 193 187 171 161 157 115 63 102 168 165 167 166 166 166 165 165 165 165 165 166 152 107 73 85 86 93 168 184 188 188 193 201 194 193 193 180 172 162 155 163 181 187 183 182 181 191 191 188 185 164 171 173 132 77 69 79 154 168 164 165 165 165 165 165 165 165 165 160 119 52 49 35 38 67 163 180 181 188 199 204 200 191 190 192 194 195 197 198 196 189 182 185 188 194 196 182 163 170 186 166 107 66 71 72 140 170 164 165 165 165 163 163 163 163 165 138 63 45 41 46 60 55 140 185 176 170 187 199 198 196 200 203 201 200 203 202 202 201 195 190 189 189 176 153 172 189 185 154 82 68 69 72 134 168 162 163 163 163 162 162 162 162 170 91 54 51 45 63 91 64 127 188 183 173 170 192 200 199 204 204 201 200 201 200 202 206 207 200 193 177 155 173 193 189 180 130 68 72 74 77 138 167 161 162 162 162 162 162 160 173 128 61 58 51 48 79 119 48 95 186 185 186 173 165 187 205 209 205 200 200 201 201 201 205 207 193 171 158 175 189 190 186 176 131 65 70 80 90 154 164 162 162 162 162 161 160 166 153 71 68 61 57 49 84 160 46 55 177 188 189 187 171 162 171 188 194 192 190 189 190 188 187 178 153 153 177 183 189 190 185 169 143 74 75 82 127 167 159 161 161 161 161 159 158 167 98 65 79 74 65 56 87 178 78 27 149 192 188 188 186 178 165 159 159 164 166 164 159 156 154 152 164 189 188 185 189 190 186 161 143 111 79 85 104 152 162 158 159 159 159 157 161 144 68 76 79 78 77 72 94 179 137 25 103 190 191 189 187 186 184 174 159 151 144 142 143 149 154 175 190 186 182 186 190 188 183 170 146 139 80 85 59 84 149 160 157 158 158\",\n          \"66 138 159 180 146 115 148 150 142 127 153 174 125 84 93 122 122 117 122 118 104 107 108 97 94 102 115 112 116 128 149 173 183 180 174 161 152 151 153 154 140 113 115 117 151 163 166 175 127 131 122 181 93 131 129 82 127 88 146 184 159 72 110 115 118 125 112 107 102 96 90 92 102 109 107 112 133 160 173 167 155 147 147 149 153 161 158 157 154 135 120 110 134 161 175 169 115 109 73 156 102 131 127 135 123 98 147 180 127 90 110 120 117 96 106 100 88 83 92 100 105 107 117 142 158 142 120 111 120 136 150 156 159 163 162 159 158 150 127 113 114 151 171 175 121 101 49 104 174 130 147 135 117 125 157 172 155 100 120 106 82 95 97 82 80 94 101 104 109 127 141 129 94 75 97 112 122 133 143 158 156 157 162 160 154 154 134 129 116 138 162 184 100 82 100 60 127 176 130 96 114 151 150 169 123 104 88 74 89 94 94 96 101 103 106 115 126 122 95 76 76 91 118 118 118 129 142 150 149 151 148 155 158 150 141 142 124 124 153 177 32 35 118 119 49 96 140 141 160 142 164 186 99 72 74 88 95 101 102 100 105 111 116 112 99 78 77 90 102 107 121 117 119 128 133 140 145 147 147 144 148 147 153 146 129 129 147 173 52 71 63 143 157 125 134 164 167 167 78 100 87 68 91 98 103 111 108 107 107 103 95 86 82 81 92 105 107 114 126 120 121 125 126 137 142 143 147 145 142 146 150 151 139 123 144 174 93 85 47 47 97 168 192 182 155 71 24 45 64 88 99 104 106 107 101 94 88 84 87 96 102 108 109 114 117 119 127 125 118 120 121 130 136 140 142 143 147 150 151 152 140 121 138 170 79 59 53 45 21 40 66 49 14 18 46 62 79 95 97 97 91 84 80 88 101 109 115 125 131 131 128 125 127 127 124 132 133 126 124 127 134 138 137 142 147 146 145 140 131 119 137 166 57 59 58 42 34 25 14 15 30 42 57 75 87 91 82 77 70 71 82 99 113 131 144 150 152 148 143 138 132 127 123 125 134 138 135 132 134 131 129 129 133 140 139 140 125 105 141 169 64 63 47 37 31 25 26 30 41 55 69 81 90 90 77 70 82 95 100 104 107 112 126 136 152 164 159 153 141 134 129 125 118 124 132 131 130 125 125 128 130 135 137 138 115 108 140 164 69 51 43 41 31 26 27 38 53 64 77 86 96 97 86 81 86 87 91 96 105 101 101 112 125 150 166 165 155 146 140 130 123 122 126 128 130 127 129 129 134 137 134 130 110 111 134 158 63 45 44 39 30 28 35 51 60 71 83 96 101 92 81 79 73 71 71 70 79 91 96 94 98 115 137 164 168 159 149 142 137 140 133 128 128 123 122 128 127 128 125 125 105 99 133 158 62 52 46 37 32 35 46 53 65 80 95 104 107 99 85 73 60 51 53 53 55 61 69 79 81 81 96 119 149 165 158 152 150 151 146 136 133 131 129 129 132 128 123 117 87 99 133 154 68 58 48 41 35 42 50 58 71 86 101 112 116 114 105 90 80 59 47 49 50 58 75 66 60 65 70 86 112 142 158 159 154 155 147 140 135 132 129 130 131 129 125 113 83 107 122 146 68 58 53 45 39 48 56 63 76 93 106 122 118 125 123 107 108 93 58 43 18 20 37 48 47 34 52 61 80 104 128 143 138 144 145 139 136 136 136 132 128 128 123 105 78 109 114 142 71 61 47 41 46 55 61 71 82 99 113 130 130 134 129 108 107 101 102 78 32 38 24 32 29 38 29 50 54 72 93 116 126 132 138 135 133 138 141 136 134 132 126 96 78 108 112 136 77 62 38 42 55 61 70 80 92 105 116 129 140 148 142 124 109 96 89 97 70 45 47 46 62 46 34 48 53 50 65 89 109 123 133 134 132 138 139 139 141 138 125 88 87 104 113 129 94 66 40 42 63 69 79 90 99 109 118 129 145 155 153 140 128 103 80 78 92 88 80 112 105 44 49 53 62 49 58 75 92 113 127 131 134 137 139 145 152 144 118 82 91 98 118 122 100 68 39 51 72 78 87 96 102 111 121 132 143 151 157 150 141 127 102 76 69 85 109 126 104 51 62 63 60 56 71 83 96 111 123 126 125 128 133 141 153 142 112 85 95 96 120 113 105 70 44 65 78 86 96 101 107 111 121 130 140 150 156 155 147 140 133 113 94 77 79 92 116 115 109 94 66 75 99 112 116 118 113 108 109 111 115 127 138 136 116 84 94 94 118 107 105 68 50 74 84 92 100 106 110 114 121 132 140 147 152 153 150 139 131 128 127 117 105 103 106 121 136 121 90 100 126 142 143 126 102 87 84 89 98 113 137 143 120 88 91 94 116 101 96 67 56 81 88 94 102 107 112 115 121 132 141 149 153 158 158 151 138 126 121 123 126 129 127 119 115 114 116 129 152 162 156 125 89 67 59 63 75 91 127 148 129 95 90 95 111 93 97 71 61 86 90 95 98 106 112 117 122 133 142 153 159 163 163 164 162 155 152 147 147 151 148 137 128 130 139 154 176 176 152 102 65 56 49 45 52 66 87 118 128 99 89 97 102 89 102 76 69 89 90 93 98 104 111 119 124 135 147 156 161 165 170 174 173 171 167 166 159 153 147 140 141 144 151 167 186 176 132 87 70 49 35 32 32 43 57 76 95 85 82 95 94 87 94 72 70 85 86 90 98 102 108 115 126 138 146 153 158 166 171 172 173 173 166 163 154 146 142 142 145 149 160 179 189 166 118 110 57 18 27 26 29 38 50 63 75 69 71 94 83 87 86 63 66 77 79 88 96 100 106 112 124 135 142 153 160 166 168 170 169 166 162 156 148 142 139 141 144 149 171 187 181 151 115 125 72 34 33 35 25 52 52 65 78 64 62 86 75 86 73 57 61 72 76 83 91 95 102 113 121 127 138 149 155 161 166 166 163 159 154 145 140 136 140 143 147 159 181 190 171 143 121 112 120 79 36 39 25 33 46 52 80 70 54 70 69 83 62 52 52 67 74 79 85 90 96 107 118 125 135 146 155 156 161 163 158 153 144 136 140 140 138 142 158 174 187 188 161 138 130 111 90 109 70 47 75 46 37 42 71 69 53 54 68 76 52 47 44 61 73 78 82 91 95 105 117 125 133 146 155 156 157 158 156 144 128 145 158 156 140 144 169 183 192 184 151 133 135 122 94 81 98 106 95 37 36 48 65 57 51 54 66 76 45 42 39 54 73 77 80 89 95 101 113 121 136 148 154 157 158 156 152 122 104 121 147 153 144 147 176 189 193 181 142 134 139 122 114 89 85 87 87 62 44 55 56 61 62 58 64 85 41 38 36 46 71 77 81 89 95 103 107 115 130 147 153 157 158 155 148 105 70 59 73 117 132 155 182 190 189 179 138 139 142 119 115 116 99 97 93 81 59 50 57 70 74 77 88 94 37 34 33 39 66 77 80 87 94 101 105 116 129 138 145 151 155 155 150 131 78 55 15 45 96 138 175 188 191 175 141 146 144 128 112 124 118 106 104 85 60 62 60 79 77 85 104 90 35 33 31 30 55 75 80 86 93 99 107 120 130 134 142 147 151 151 153 148 123 90 68 36 59 103 148 175 185 164 146 153 151 139 123 120 119 114 107 67 64 77 70 77 92 92 93 88 33 30 27 26 43 71 78 84 93 100 107 117 126 135 142 144 147 149 153 149 143 122 92 61 54 71 107 141 155 141 154 156 157 150 137 128 127 125 89 56 67 77 83 81 95 94 89 116 28 28 26 25 31 64 76 79 87 96 100 106 106 100 120 142 145 145 149 149 145 137 114 76 55 57 67 82 80 105 155 158 158 154 144 136 133 113 64 65 65 75 87 85 87 90 102 105 27 27 27 26 24 51 73 77 81 86 95 107 109 72 43 73 111 135 146 150 148 147 126 100 85 91 86 64 64 123 160 157 156 153 147 137 120 76 66 73 66 77 87 81 86 98 103 98 27 27 28 26 24 37 68 78 80 81 90 105 124 127 87 44 33 55 91 123 151 163 141 122 128 132 122 116 142 163 159 155 154 149 142 128 85 62 72 73 73 78 87 84 88 97 100 99 27 27 27 26 26 28 57 78 84 86 89 96 111 123 124 113 90 52 24 45 96 153 168 154 151 144 145 149 154 159 156 148 143 141 136 99 71 72 74 73 75 84 91 82 88 97 98 93 26 25 25 25 26 25 43 72 83 92 96 97 99 108 117 109 106 114 86 30 31 89 145 162 159 148 151 150 154 157 146 138 136 138 107 71 74 79 75 72 79 85 85 78 93 94 97 83 26 24 25 25 25 25 31 62 80 90 96 97 92 88 94 105 106 110 121 95 43 32 48 91 142 145 145 145 149 145 134 129 132 107 66 64 65 64 63 68 77 84 76 85 92 92 89 72 25 24 25 26 25 24 24 47 75 88 99 105 106 96 80 79 85 93 115 128 117 80 38 24 85 134 136 137 139 130 120 118 97 54 54 54 50 52 58 65 76 76 76 83 83 87 86 64 25 25 25 24 24 24 22 32 65 86 105 117 122 120 107 84 71 61 64 93 119 123 100 53 28 88 124 126 120 109 96 84 69 52 60 55 50 53 58 66 67 68 75 76 83 95 74 43 26 26 26 24 24 24 24 24 47 79 100 117 127 134 139 135 120 99 73 56 78 107 112 114 81 63 100 108 97 78 59 60 76 59 59 63 46 49 63 65 63 73 74 73 89 91 49 26 28 28 26 24 25 24 24 25 31 59 84 103 118 128 137 146 153 146 117 82 71 83 104 116 108 93 89 74 45 34 45 66 89 74 57 70 49 42 60 44 68 90 84 77 87 77 39 24 28 32 28 24 24 25 26 27 28 36 58 84 101 115 125 137 148 149 141 117 97 89 92 95 81 75 56 33 13 22 26 46 91 91 57 63 57 26 64 36 56 103 99 89 90 70 31 23 31 37 35 30 26 27 29 31 33 39 37 51 78 97 106 121 132 140 141 126 110 94 81 73 67 60 47 29 12 12 29 21 55 89 67 53 87 55 55 79 62 94 87 92 94 62 27 21 36 44 46 40 32 29 31 34 38 46 51 39 42 65 83 100 115 126 130 114 93 78 77 75 69 65 54 28 9 16 50 13 16 65 85 68 67 103 93 105 110 85 85 88 79 52 24 15\",\n          \"92 79 78 75 69 76 85 89 84 89 97 101 107 110 110 113 117 114 92 88 169 224 227 235 177 178 199 143 176 158 173 187 199 214 232 213 195 152 176 248 253 251 253 255 105 17 31 193 94 86 93 88 87 92 94 89 89 103 107 107 111 109 114 110 108 88 147 177 215 230 177 171 127 132 161 128 142 142 121 121 124 156 175 198 208 216 225 250 252 252 252 255 119 17 30 166 95 95 108 105 105 101 102 96 96 108 108 109 109 109 109 97 98 136 217 228 218 206 139 124 141 137 136 142 145 146 143 142 134 106 64 159 200 217 224 246 253 251 252 255 129 15 29 113 103 109 119 118 109 105 101 95 104 112 111 108 108 102 95 118 190 215 223 226 216 184 152 141 146 145 146 151 156 155 150 152 148 133 83 68 166 197 216 237 254 251 252 255 135 15 27 96 114 118 119 115 108 104 101 106 112 114 112 106 91 101 188 223 225 214 204 212 197 154 143 145 147 146 150 159 158 156 155 157 154 140 107 56 122 189 197 221 253 252 252 255 159 20 22 112 119 118 122 121 117 113 109 116 117 115 119 95 105 210 241 227 206 205 206 174 144 149 145 148 149 151 153 161 160 156 160 161 158 147 124 75 114 172 187 215 243 252 252 255 198 29 19 98 127 128 123 122 123 121 124 118 116 117 96 111 194 218 224 230 153 146 159 142 145 149 149 151 152 153 155 159 161 160 162 165 161 148 139 85 105 167 185 222 247 252 254 255 246 74 11 85 136 130 118 119 126 123 125 110 97 96 138 216 234 223 192 164 149 125 137 143 146 152 153 155 153 155 156 159 161 161 162 164 159 150 147 104 104 166 189 214 250 250 254 253 255 124 15 48 142 131 115 121 122 119 123 105 88 182 223 212 208 200 161 116 140 137 142 146 148 153 156 155 156 157 155 159 162 163 162 161 152 148 143 103 101 173 184 215 249 250 255 252 255 151 28 33 140 128 121 125 119 114 96 104 185 242 210 213 208 139 133 136 137 141 141 144 148 151 154 154 158 158 158 161 164 164 159 150 133 115 99 83 87 152 195 223 248 250 255 252 255 175 40 34 137 123 123 119 109 93 136 209 232 227 180 187 171 131 134 139 138 139 140 142 143 146 150 152 155 157 158 161 164 164 153 123 84 73 74 87 99 159 209 239 252 251 255 252 255 188 35 45 130 122 123 94 97 158 219 227 199 166 175 132 135 131 126 124 129 128 123 124 127 129 137 146 154 157 161 161 164 165 142 103 112 124 129 147 136 169 217 253 252 252 255 253 255 201 31 45 120 105 116 124 200 217 197 229 211 102 122 126 123 112 99 94 81 68 71 85 100 110 127 142 151 158 162 162 167 163 140 142 155 158 165 186 149 174 219 249 253 252 255 252 255 214 37 48 108 114 205 218 237 217 171 165 142 123 119 109 105 98 87 69 64 88 111 123 130 128 132 144 154 161 163 162 170 162 153 160 157 156 172 185 143 186 220 248 253 252 255 252 255 232 45 60 96 136 235 215 217 231 183 113 126 136 120 118 121 114 112 119 135 147 150 146 145 143 142 148 157 162 164 166 173 157 154 114 76 76 139 155 109 189 219 250 254 252 253 251 255 235 48 76 152 220 214 213 203 178 144 143 150 142 144 151 148 145 150 155 155 155 156 147 144 144 143 148 156 162 164 168 164 155 97 25 39 82 64 91 113 177 227 254 252 252 253 250 255 235 50 98 229 225 216 198 131 123 144 157 160 163 168 164 163 160 154 134 104 84 88 125 144 138 139 147 154 159 162 169 158 137 40 35 79 136 133 131 113 160 225 254 253 252 252 248 255 239 50 117 230 224 207 144 129 153 160 166 170 171 170 169 164 132 84 42 21 26 29 60 128 135 134 142 152 157 160 167 160 129 58 50 71 108 164 181 111 166 211 251 253 252 252 247 254 238 49 137 218 240 144 138 153 162 168 170 170 168 163 147 99 62 79 37 29 41 65 70 84 146 126 139 151 158 162 169 158 146 136 126 122 137 184 195 119 164 199 243 255 252 251 246 253 233 52 170 74 105 121 151 166 172 176 172 171 161 140 114 84 78 107 72 35 35 74 103 112 141 127 141 152 155 158 166 164 149 143 138 146 163 185 204 137 158 189 233 255 252 250 244 255 218 46 191 29 70 142 165 175 178 180 177 174 166 159 152 147 142 126 116 103 104 120 131 138 136 129 144 154 154 155 161 173 163 156 147 151 163 176 209 149 139 186 230 254 251 249 242 253 213 48 201 140 98 148 171 180 183 184 182 176 174 169 165 162 159 156 150 140 131 129 130 139 141 139 152 156 154 157 157 174 183 166 164 162 167 174 209 163 139 186 228 253 251 248 240 250 214 57 208 90 97 155 174 183 186 188 188 181 176 173 168 163 160 158 152 140 136 135 141 150 144 148 157 159 157 156 155 164 193 178 170 171 173 177 208 174 145 183 217 251 251 245 235 243 221 76 217 60 103 157 175 186 190 191 191 186 180 177 172 167 161 158 153 147 144 146 151 152 149 152 159 160 158 158 157 159 188 189 173 174 177 182 206 187 132 160 208 247 252 242 232 239 229 89 223 67 104 157 178 188 193 194 192 189 185 180 174 170 166 163 158 156 155 156 158 156 153 155 159 158 160 160 159 158 178 192 173 175 180 185 205 195 153 158 194 240 253 240 229 233 238 96 211 68 106 155 178 188 193 195 193 190 186 181 179 175 171 168 166 164 161 161 161 159 155 155 159 160 164 164 164 162 170 187 167 174 179 184 206 192 146 168 186 236 254 241 230 228 247 114 163 73 101 149 175 186 192 195 194 192 187 184 182 179 177 173 171 168 166 166 163 157 152 148 150 155 158 166 166 166 168 186 168 168 179 184 206 186 147 163 180 231 254 240 229 226 241 157 117 78 103 140 169 180 190 196 195 195 191 186 186 183 180 178 175 173 171 169 164 156 147 138 146 154 160 164 164 166 167 183 177 163 178 183 207 180 144 165 188 237 255 249 245 243 241 235 221 82 106 133 160 177 187 191 191 193 193 190 188 185 181 181 177 178 174 170 164 157 140 136 156 166 169 172 163 165 168 183 183 163 177 184 209 168 149 166 193 239 255 253 254 255 255 255 255 87 108 130 152 173 184 188 191 193 193 191 189 185 183 182 180 177 174 171 167 154 139 133 155 175 170 150 160 170 170 170 165 165 177 187 207 158 141 148 189 246 254 253 254 255 255 254 254 86 110 132 147 168 180 185 190 192 193 190 187 185 183 182 179 177 174 170 166 152 143 132 136 151 129 126 148 158 157 159 163 166 177 195 190 141 142 144 187 246 253 253 255 255 255 255 255 80 107 132 149 163 175 181 187 189 189 189 187 184 182 181 178 176 174 170 162 151 147 148 141 141 143 146 148 151 165 165 168 170 178 202 155 124 153 153 193 244 254 253 255 255 255 255 252 79 100 129 150 161 170 179 185 186 184 188 185 181 182 181 177 173 171 166 157 148 152 151 149 150 150 151 152 155 165 169 170 172 183 195 131 134 151 164 198 245 253 252 255 255 255 254 255 69 101 122 146 161 168 176 182 182 182 181 180 179 180 177 175 173 167 158 151 150 152 151 150 148 149 153 150 149 162 174 171 165 194 164 121 134 147 167 197 243 253 252 255 255 253 255 137 47 94 120 138 156 167 175 178 178 180 177 178 177 177 174 172 169 164 158 153 149 147 148 149 149 149 148 151 151 155 174 160 165 191 124 119 143 155 161 196 247 251 252 255 252 255 186 23 24 71 115 134 149 163 172 175 175 175 175 175 174 173 171 167 164 160 153 152 152 154 155 152 142 129 125 143 143 134 140 151 183 169 107 132 155 155 165 198 246 250 251 254 254 238 50 15 21 39 94 127 145 158 166 171 173 173 172 171 171 170 169 166 164 156 142 105 99 98 95 93 89 95 96 85 86 120 146 162 187 126 105 137 149 159 170 195 239 251 251 251 255 126 40 84 23 23 58 109 135 148 159 165 169 171 170 169 168 169 167 165 164 158 132 80 58 51 52 51 51 54 55 61 109 155 158 176 149 101 118 148 151 160 173 191 240 252 249 255 236 88 111 109 23 27 39 79 119 137 150 157 161 165 166 168 170 168 166 165 164 155 133 132 119 108 105 101 103 101 106 120 145 163 170 162 113 114 127 157 164 163 169 193 244 252 251 230 141 99 106 101 24 27 35 54 90 121 139 153 158 160 163 162 165 165 163 164 163 151 141 139 140 135 123 121 123 120 121 131 161 170 172 116 107 124 135 160 167 157 171 198 247 250 255 154 67 113 85 56 27 30 29 39 66 100 125 141 149 156 158 157 159 160 157 158 154 150 151 146 145 147 145 135 134 137 140 158 168 176 128 95 116 126 138 153 155 162 177 194 233 251 255 162 97 107 58 55 29 40 49 33 31 61 102 127 136 144 149 152 155 157 158 158 155 155 152 151 150 150 149 148 147 152 161 165 173 162 105 99 112 125 137 155 162 170 176 193 225 252 255 182 121 93 54 60 31 48 72 80 49 24 39 85 126 138 142 147 152 154 158 159 159 158 154 154 151 154 154 151 151 158 161 173 167 122 128 107 109 128 143 161 178 168 177 196 231 252 255 180 116 92 57 59 37 50 80 100 111 87 51 28 53 104 134 141 142 144 151 154 153 154 157 158 155 157 157 157 158 163 168 181 124 98 151 119 118 132 144 158 174 172 178 189 214 251 254 148 106 102 63 58 50 58 76 100 122 133 133 110 66 46 65 105 132 139 142 144 147 153 155 158 160 159 157 157 160 164 175 142 94 102 134 136 123 133 137 148 166 174 176 190 212 248 255 108 94 107 86 56 59 68 72 96 120 134 147 154 141 121 84 62 70 92 115 130 142 149 152 158 160 160 159 155 153 162 151 95 108 107 166 159 121 131 144 149 174 182 175 190 222 250 255 102 67 118 101 99 60 71 81 94 115 129 140 152 149 143 140 130 113 98 92 97 107 128 142 148 151 152 149 149 149 162 149 106 111 102 145 166 136 138 150 156 169 183 176 187 204 236 255 104 20 84 108 105 74 71 85 98 105 123 139 153 154 150 148 149 146 145 141 136 130 130 140 143 147 155 157 163 171 179 139 108 116 114 128 164 151 146 152 149 163 186 186 189 210 220 254 104 29 27 39 61\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_link = '/kaggle/input/emo-map-challenge/test_dataset.csv'\n",
        "test_df = pd.read_csv(test_link)\n",
        "test_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T08:16:19.164684Z",
          "iopub.execute_input": "2024-09-16T08:16:19.165011Z",
          "iopub.status.idle": "2024-09-16T08:16:19.663068Z",
          "shell.execute_reply.started": "2024-09-16T08:16:19.164977Z",
          "shell.execute_reply": "2024-09-16T08:16:19.661953Z"
        },
        "trusted": true,
        "id": "irAIv2hu6Amx",
        "outputId": "a1025277-2ea5-4557-8f95-4fd7de5d356d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                             pixels\n",
              "0     5001  80 81 77 69 66 59 70 89 112 132 140 142 144 14...\n",
              "1     5002  226 226 226 217 203 189 97 149 193 193 199 200...\n",
              "2     5003  98 112 43 41 46 47 67 37 27 37 65 32 39 29 41 ...\n",
              "3     5004  35 38 29 25 21 29 35 32 41 49 34 68 123 136 11...\n",
              "4     5005  4 1 5 19 14 15 21 50 73 73 61 62 72 76 66 55 6...\n",
              "...    ...                                                ...\n",
              "2495  7496  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...\n",
              "2496  7497  178 174 172 173 181 188 191 194 196 199 200 20...\n",
              "2497  7498  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...\n",
              "2498  7499  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...\n",
              "2499  7500  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...\n",
              "\n",
              "[2500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5eea130e-0869-4f98-9f1c-5f05a5ceca9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5001</td>\n",
              "      <td>80 81 77 69 66 59 70 89 112 132 140 142 144 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5002</td>\n",
              "      <td>226 226 226 217 203 189 97 149 193 193 199 200...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5003</td>\n",
              "      <td>98 112 43 41 46 47 67 37 27 37 65 32 39 29 41 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5004</td>\n",
              "      <td>35 38 29 25 21 29 35 32 41 49 34 68 123 136 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5005</td>\n",
              "      <td>4 1 5 19 14 15 21 50 73 73 61 62 72 76 66 55 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>7496</td>\n",
              "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>7497</td>\n",
              "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>7498</td>\n",
              "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>7499</td>\n",
              "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>7500</td>\n",
              "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5eea130e-0869-4f98-9f1c-5f05a5ceca9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5eea130e-0869-4f98-9f1c-5f05a5ceca9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5eea130e-0869-4f98-9f1c-5f05a5ceca9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51807e7d-72ed-4073-8d3b-35c71919ac47\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51807e7d-72ed-4073-8d3b-35c71919ac47')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51807e7d-72ed-4073-8d3b-35c71919ac47 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0f382d9c-6270-4412-992c-704d05858c0a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0f382d9c-6270-4412-992c-704d05858c0a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 2500,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 721,\n        \"min\": 5001,\n        \"max\": 7500,\n        \"num_unique_values\": 2500,\n        \"samples\": [\n          6448,\n          6115,\n          6065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pixels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2490,\n        \"samples\": [\n          \"28 35 31 31 28 28 50 23 3 3 1 1 1 0 1 4 13 31 46 54 58 62 67 74 78 79 79 80 80 86 89 79 71 59 36 34 19 7 7 12 10 9 12 16 13 2 0 16 27 33 30 28 24 43 37 4 2 1 1 0 1 1 2 7 32 53 54 58 64 68 75 79 84 88 90 93 95 101 103 96 87 78 56 50 49 22 14 16 16 12 22 19 13 3 0 4 30 30 28 22 28 52 17 3 3 2 2 3 2 1 13 42 65 70 63 61 66 73 80 84 89 94 97 99 103 109 111 108 106 104 86 74 77 55 36 23 17 17 21 18 17 13 1 0 31 31 25 20 44 28 4 3 2 3 3 10 12 22 48 75 83 81 76 69 69 73 80 86 94 99 101 102 106 114 117 118 120 120 109 92 90 81 58 46 25 10 12 12 8 6 1 0 19 26 21 37 45 12 5 2 1 2 6 16 24 43 65 81 89 88 81 72 72 74 80 89 95 100 103 104 109 118 123 125 129 130 125 115 105 101 75 58 38 14 6 6 4 0 0 0 15 16 28 57 29 12 3 2 2 1 7 21 34 53 75 88 94 91 82 73 72 76 82 91 96 100 103 108 112 121 127 129 134 135 136 136 133 133 109 80 53 25 4 3 4 0 0 0 12 12 46 43 17 5 2 2 2 3 17 40 52 63 82 96 99 89 78 71 75 79 87 95 98 101 104 109 112 120 128 133 138 137 140 145 148 144 131 116 80 40 13 1 0 0 0 0 19 36 59 23 11 0 2 2 1 7 41 60 62 70 87 100 98 86 76 75 76 82 89 95 100 103 106 111 114 120 126 133 138 138 139 144 143 143 133 124 111 71 29 3 0 0 0 0 55 74 44 19 8 1 3 2 1 17 54 63 67 79 93 99 96 85 72 72 77 83 90 96 100 105 110 114 119 122 126 130 133 135 136 136 136 134 131 124 118 101 48 7 0 1 1 0 91 72 30 18 4 2 5 2 2 32 62 63 69 85 101 100 94 82 71 74 79 84 91 98 102 108 113 118 122 125 128 130 131 135 136 135 134 131 128 123 118 111 65 15 0 1 1 0 91 48 28 9 1 1 3 2 6 41 64 63 70 88 98 99 95 80 74 84 87 86 94 107 106 111 118 123 125 127 128 130 135 138 140 137 136 134 131 127 120 116 89 38 3 0 0 0 70 37 27 8 1 3 2 2 9 44 62 63 73 85 86 72 62 59 65 82 91 96 105 110 107 114 120 123 127 128 128 133 138 138 141 138 135 132 131 126 120 112 103 74 18 0 0 0 54 41 25 5 2 4 3 0 12 47 62 63 81 99 109 97 70 51 42 39 49 71 108 109 103 114 120 121 129 129 130 137 139 137 141 139 134 131 129 125 120 113 104 87 48 10 0 0 57 38 21 5 2 2 2 1 21 51 62 64 85 103 102 96 86 74 58 40 31 29 69 108 106 105 114 119 126 128 130 137 137 137 140 138 135 133 127 123 122 115 106 87 56 25 4 0 53 33 19 3 1 0 0 4 30 54 60 66 76 72 71 58 42 43 56 52 38 36 36 65 93 97 105 113 119 122 125 130 132 133 137 138 137 132 123 121 124 118 106 93 65 25 10 3 43 30 16 4 1 0 0 9 41 61 70 71 69 48 30 17 7 3 14 27 44 43 45 48 71 85 94 107 118 118 120 126 135 135 139 144 146 143 126 120 122 117 106 99 77 33 13 11 42 25 11 4 1 1 0 17 50 66 74 70 73 59 43 67 30 13 38 23 34 55 53 55 66 77 90 110 119 109 108 109 98 81 78 84 105 137 129 123 120 116 106 101 81 40 13 7 36 19 7 1 1 1 0 27 58 73 79 73 75 78 74 90 56 20 50 110 80 50 66 57 61 75 96 122 122 106 88 69 49 41 38 40 54 80 99 109 117 115 108 102 85 42 14 3 27 16 9 2 1 0 2 40 69 79 84 84 85 92 82 70 72 60 97 109 84 60 70 60 56 75 106 131 124 110 92 70 50 52 57 64 69 83 90 81 93 110 107 101 85 39 11 2 31 15 7 3 1 0 9 50 75 80 84 84 87 98 101 92 73 71 74 74 67 72 64 57 58 83 119 136 120 111 99 63 40 35 35 58 78 78 103 109 94 96 103 99 80 28 5 1 33 14 4 3 1 0 12 61 80 80 84 86 92 100 104 105 97 89 89 88 80 73 62 59 67 98 130 137 123 114 85 55 36 12 28 19 36 71 63 102 115 105 97 100 75 15 1 2 27 15 4 8 4 0 15 69 82 80 87 96 102 109 112 113 113 107 97 87 81 72 63 60 81 111 129 135 122 114 88 70 48 18 34 63 52 20 48 69 107 105 99 98 55 3 1 1 24 16 6 8 4 0 18 76 81 79 92 100 105 114 116 118 117 109 94 89 88 76 66 63 86 112 121 131 121 114 100 72 63 46 49 93 89 29 28 55 88 97 99 95 35 1 2 1 25 13 7 4 2 0 15 73 80 84 95 102 110 119 119 117 116 107 94 91 86 74 68 65 87 108 121 132 120 123 112 91 81 83 75 76 64 56 54 55 87 97 98 80 17 0 1 1 21 8 6 4 1 0 21 67 78 82 97 109 121 125 124 119 121 110 93 88 83 77 64 63 85 107 129 131 120 131 131 115 95 89 91 94 95 102 106 95 108 102 99 60 14 1 1 0 19 5 6 3 0 1 33 67 74 81 98 113 127 133 135 126 118 107 94 92 88 71 58 64 91 112 126 125 122 132 143 134 122 109 102 104 113 113 112 119 114 103 93 41 10 1 1 0 19 6 4 2 1 5 41 66 70 77 93 110 125 134 136 124 111 103 101 94 81 62 59 71 106 120 125 125 124 132 140 141 134 125 120 114 111 110 116 119 112 103 79 26 9 3 0 0 14 5 2 2 1 11 48 66 71 73 88 105 116 123 122 114 104 98 91 82 67 60 63 91 131 140 134 123 121 129 136 143 143 131 127 122 118 120 120 114 106 100 62 20 11 4 0 0 6 1 1 1 0 24 56 68 71 72 84 99 109 113 113 107 95 89 90 78 61 61 68 98 130 149 138 121 118 121 134 144 147 141 136 129 125 124 120 109 101 94 51 17 14 3 0 0 6 1 1 0 1 35 63 73 73 73 79 92 103 108 108 100 96 102 104 93 63 50 60 81 99 113 119 124 119 107 128 146 153 154 145 134 128 122 114 105 99 81 40 14 7 1 0 0 3 1 1 0 5 41 66 77 77 73 75 87 98 104 104 103 110 109 105 102 84 61 57 67 86 91 71 90 123 98 112 137 147 149 143 136 126 118 111 105 94 61 27 6 0 1 1 1 2 2 2 0 11 49 71 80 79 73 71 85 95 104 108 111 115 110 102 96 87 79 83 85 102 117 109 112 132 99 90 120 128 128 128 128 125 118 108 101 85 56 16 2 1 1 1 1 2 2 1 0 16 54 74 84 83 77 74 85 96 107 110 115 118 111 100 94 92 96 119 122 129 135 137 137 136 113 85 105 115 119 120 120 118 112 104 92 86 61 13 1 1 1 0 1 2 1 1 0 17 55 75 84 84 81 77 86 97 106 110 118 119 109 98 93 92 102 121 120 131 132 130 132 136 126 93 93 106 113 114 115 111 106 97 90 91 55 9 6 5 2 2 1 2 1 1 0 14 55 73 82 85 82 78 87 99 105 109 116 114 101 90 91 95 108 118 122 130 129 130 133 134 130 111 98 100 108 110 111 105 100 94 94 75 42 7 12 11 7 4 2 1 0 0 0 10 52 72 83 86 82 80 89 98 98 93 89 79 68 59 56 65 84 114 124 131 134 132 134 134 124 115 106 99 106 108 106 101 97 91 81 73 43 4 9 6 4 1 5 2 0 0 0 6 47 68 81 86 81 79 89 94 96 88 50 35 41 67 73 68 54 59 71 86 106 123 131 131 121 110 106 99 101 103 99 96 104 79 68 103 47 1 2 0 1 0 6 2 1 1 1 1 24 58 75 86 83 77 87 96 100 105 67 51 96 85 93 105 92 85 73 64 60 74 110 123 118 106 105 100 96 97 96 98 103 68 43 51 6 2 1 0 1 0 4 1 0 1 1 1 3 42 68 84 85 78 84 95 102 100 86 78 83 100 108 98 96 112 102 76 49 38 60 97 108 107 110 102 98 98 98 98 99 55 17 4 0 2 0 0 0 1 6 1 0 1 1 1 0 14 58 84 86 81 85 95 101 99 95 95 88 82 86 95 107 108 113 102 68 38 54 83 102 109 106 103 102 100 99 99 91 43 17 6 0 1 0 0 0 1 7 1 0 1 1 1 1 0 24 80 87 84 87 93 96 100 96 93 90 89 86 77 73 76 81 90 92 92 104 112 104 106 103 104 104 103 102 103 68 31 14 3 1 1 1 1 1 2 5 1 0 0 0 0 0 2 1 52 87 81 87 90 93 99 100 98 90 77 76 90 95 100 101 106 104 100 109 110 105 104 103 102 103 103 103 94 41 24 11 2 2 2 1 1 3 3 6 1 0 0 0 0 0 1 1 11 66 80 81 84 94 102 103 102 98 88 80 79 77 80 89 95 102 104 108 108 100 99 100 99 100 99 99 69 30 24 12 1 3 3 1 1 3 5 7 1 1 1 1 0 0 0 1 0 26 73 72 78 96 105 109 110 109 114 109 99 93 91 94 100 103 104 104 102 97 95 96 98 96 98 70 27 28 19 7 15 21 5 2 0 3 10 9 1 1 1 1 0 0 0 0 1 3 36 65 76 92 106 117 123 118 124 128 125 120 111 108 109 105 105 102 98 94 94 94 92 90 71 23 16 20 13 4 31 36 13 4 1 5 15 13 2 1 0 0 0 0 0 0 1 3 23 41 65 85 102 115 121 124 125 129 132 134 123 116 115 112 108 104 101 95 89 81 87 74 12 11 26 21 13 11 36 29 18 5 3 13 17 16 2 2 0 0 0 0 0 0 0 1 21 32 40 72 98 104 108 116 121 123 128 129 123 118 115 113 109 100 92 84 83 99 108 41 0 9 25 21 15 21 37 25 19 8 8 15 17 16 2 2 0 0 0 0 0 0 0 1 15 35 36 52 82 92 98 104 107 106 113 115 116 113 111 108 101 90 90 100 110 113 85 11 3 9 26 21 15 29 32 23 16 8 9 10 19 16\",\n          \"197 198 192 176 164 81 88 119 169 141 120 141 126 170 132 134 106 58 72 62 67 59 66 59 44 40 33 31 31 28 13 7 29 61 55 91 116 96 83 86 98 170 193 189 157 182 162 190 220 199 169 155 93 109 123 159 150 116 127 174 98 86 156 93 58 84 85 94 95 87 92 82 71 62 47 47 43 39 29 18 0 7 29 36 51 58 59 86 88 92 110 175 169 178 177 159 170 171 137 81 105 129 154 138 110 138 164 124 117 141 82 72 98 100 113 124 131 129 124 117 108 95 81 75 65 56 45 34 16 2 0 7 13 22 56 70 54 61 83 94 118 173 200 161 122 109 79 89 142 152 132 102 148 155 133 140 110 66 88 104 110 121 134 144 149 155 150 147 136 126 111 98 88 75 56 47 29 9 5 9 25 6 13 27 64 92 68 86 92 98 137 188 87 64 101 128 136 102 83 166 126 137 133 84 75 97 104 115 133 145 157 170 177 173 173 174 166 155 137 129 126 102 81 75 59 32 11 4 28 32 19 10 7 17 74 64 84 121 126 127 126 107 137 129 103 96 137 131 139 103 63 94 98 107 121 142 161 171 179 187 191 187 187 184 181 175 164 157 151 135 118 104 84 64 36 11 20 58 43 22 24 16 62 74 48 59 61 148 110 122 84 90 110 126 162 131 97 85 80 99 115 129 148 166 176 184 192 194 196 189 190 189 186 183 181 174 162 155 137 129 110 82 66 36 19 68 68 42 26 33 51 80 119 68 37 94 87 66 96 102 106 199 140 104 82 80 90 112 132 148 164 177 185 193 198 198 198 192 194 193 186 183 176 168 160 146 132 116 95 79 74 51 20 66 79 62 32 43 38 60 127 122 52 88 69 116 134 119 174 167 87 82 90 94 108 132 148 163 173 180 189 195 200 200 202 200 195 193 188 180 169 157 142 136 126 105 108 128 119 99 39 58 79 76 44 55 35 56 102 137 65 87 92 127 101 166 153 118 104 119 98 114 130 146 158 168 175 184 190 193 202 204 205 204 200 194 185 181 169 158 140 133 136 144 152 149 148 138 77 60 83 79 57 60 56 38 72 130 98 62 131 74 152 170 99 85 104 103 104 119 136 148 160 165 171 182 192 198 202 206 204 203 197 196 186 179 171 165 163 147 119 91 76 79 105 111 96 64 79 83 66 83 79 39 70 107 82 74 119 144 161 146 86 85 103 79 98 116 126 135 148 156 168 177 189 198 202 203 204 201 199 197 189 182 174 174 137 57 17 12 9 23 29 48 63 60 72 85 79 104 107 41 64 123 68 67 159 186 120 114 97 100 78 74 93 110 114 128 140 151 164 175 187 197 202 204 202 204 203 196 187 178 179 149 71 12 55 68 50 16 25 26 37 55 81 94 87 108 128 44 61 80 64 78 143 157 125 99 105 107 89 107 106 115 111 133 150 148 154 167 180 188 196 203 204 209 207 199 189 187 186 147 86 98 188 130 151 55 74 39 34 50 80 97 79 111 149 49 52 76 66 97 135 98 115 75 111 110 109 89 56 38 31 41 100 153 155 151 165 180 192 206 210 211 210 202 194 202 190 155 217 99 136 101 161 79 130 111 28 35 83 93 70 113 168 63 47 96 60 83 89 133 90 107 107 70 30 4 2 21 35 22 7 65 151 162 156 173 192 207 214 217 214 207 202 220 152 168 238 172 87 118 87 83 144 106 87 46 89 95 69 127 189 87 59 95 68 90 107 90 103 121 70 21 7 52 30 82 80 148 129 24 90 182 173 175 192 210 217 220 217 212 208 217 194 199 208 210 176 153 151 156 159 179 170 98 86 98 80 137 204 112 73 99 90 118 108 92 121 74 26 1 72 140 31 122 126 121 159 84 138 141 203 180 194 210 217 219 217 214 212 209 219 213 206 200 202 205 203 196 201 199 194 163 97 101 89 141 218 134 69 123 122 106 112 123 90 64 39 38 102 194 141 72 114 111 76 162 193 178 203 186 197 211 218 218 217 214 211 209 208 209 204 202 202 204 206 207 207 204 199 194 153 108 94 139 231 156 93 130 147 124 99 76 88 75 56 63 85 133 157 127 92 126 175 203 195 206 195 188 200 211 215 217 218 215 214 211 206 207 212 209 206 206 206 206 208 206 203 194 188 146 98 155 233 175 118 146 183 95 70 82 86 82 96 107 114 106 121 154 179 189 193 194 198 201 190 194 205 213 216 217 219 215 214 217 213 208 211 211 211 209 207 206 204 203 200 193 185 175 113 174 231 181 130 152 196 127 75 87 79 91 124 148 164 180 189 195 196 198 199 203 206 201 194 204 211 213 219 221 221 217 214 217 220 217 215 213 211 211 210 208 206 203 201 196 187 176 133 203 222 182 116 145 208 150 81 81 85 105 138 160 174 186 190 196 198 199 202 205 206 202 204 211 209 210 220 223 225 221 217 215 215 220 221 219 216 215 213 213 209 206 203 199 192 178 149 221 222 166 95 157 211 168 76 81 89 110 140 161 180 190 192 193 196 200 205 205 205 208 213 213 206 215 224 226 228 227 224 216 210 216 222 223 221 218 217 216 216 213 210 206 195 174 160 227 219 147 67 154 219 196 81 82 94 119 147 168 182 190 191 194 198 202 206 208 210 216 218 210 205 216 219 223 225 224 220 220 217 216 216 221 223 222 219 220 220 219 216 211 204 181 171 228 210 121 105 139 229 215 86 85 99 118 146 169 179 187 193 197 202 206 209 213 218 221 216 210 212 213 214 212 215 212 221 211 217 224 214 215 220 222 222 222 222 221 219 216 210 190 174 226 212 64 95 158 226 224 86 91 105 120 145 171 184 191 199 204 209 211 214 218 221 220 213 215 221 207 188 205 195 208 148 20 78 197 212 211 217 220 222 223 222 222 221 217 213 194 170 223 208 86 66 121 226 231 91 94 107 129 149 168 183 193 201 208 212 216 219 221 222 219 212 215 203 73 15 135 192 196 172 119 158 182 193 206 216 219 221 223 224 222 220 218 215 202 172 217 205 119 90 84 186 235 88 97 108 132 154 171 185 195 205 213 217 221 222 223 223 218 208 203 190 162 148 180 198 206 222 234 222 201 207 217 220 219 219 220 222 222 222 218 214 202 172 204 213 139 107 88 151 232 80 96 111 131 154 172 187 198 207 214 219 222 224 225 225 222 214 198 190 203 222 222 222 223 224 222 221 224 225 223 222 221 220 221 222 222 220 217 212 202 172 186 220 143 112 99 118 214 64 93 113 129 150 171 190 199 207 213 219 223 225 226 225 224 223 223 219 218 221 223 225 224 225 225 223 222 221 222 222 221 221 221 222 220 217 215 211 202 174 170 220 162 116 100 94 169 52 87 114 134 154 172 190 198 207 213 218 223 225 227 226 226 224 225 225 224 224 225 224 224 225 226 223 220 219 220 220 222 221 219 221 218 215 213 206 196 180 163 212 189 126 110 113 126 35 73 114 136 159 174 187 198 206 211 217 222 225 226 226 225 224 223 223 222 223 224 229 227 226 223 224 224 221 218 219 220 220 218 217 215 215 212 208 198 185 167 188 214 143 111 106 100 52 59 102 137 156 173 184 195 202 208 213 220 224 225 226 225 225 223 222 222 225 227 209 204 207 185 186 197 217 223 219 216 214 215 211 210 212 212 208 199 184 170 167 215 193 121 108 99 58 65 84 136 155 171 180 192 199 207 213 217 221 224 225 224 224 224 222 225 221 189 174 166 166 166 171 156 155 188 212 216 212 204 207 207 207 210 207 200 186 175 162 182 228 156 116 85 55 76 75 117 151 167 178 188 196 203 210 215 217 221 220 221 224 222 225 214 168 144 150 141 144 131 75 53 79 91 114 143 143 179 201 208 210 207 203 194 183 170 169 151 198 210 123 85 53 64 52 85 154 166 175 182 191 197 205 210 214 216 216 218 221 220 218 164 93 76 59 60 55 47 62 104 137 150 138 122 145 195 206 210 209 206 200 192 182 167 166 148 129 226 173 90 51 57 39 27 134 160 169 178 189 196 203 208 210 212 213 213 212 210 163 94 98 138 156 165 167 177 198 211 206 196 199 205 219 218 214 209 206 203 199 190 179 164 156 136 105 178 230 124 24 17 34 18 87 158 165 177 186 193 200 205 208 208 207 202 196 129 82 154 195 207 214 215 216 210 203 200 190 189 197 205 211 216 214 209 202 199 193 185 170 154 143 109 90 157 204 221 21 19 20 29 48 144 162 175 181 191 200 202 205 205 203 198 193 172 182 205 194 186 189 189 186 183 169 171 187 194 199 207 211 214 212 207 200 192 185 176 162 140 122 71 83 159 178 213 34 37 31 26 28 105 152 168 178 188 195 199 201 202 201 201 209 220 215 203 195 189 183 170 156 158 163 172 188 198 203 208 211 212 209 204 197 190 176 164 145 132 68 52 101 136 183 185 73 36 30 31 21 52 135 153 170 179 188 194 196 195 196 201 206 207 200 193 189 186 183 183 181 187 192 193 198 206 210 210 209 208 207 199 192 182 166 145 132 92 15 79 121 82 173 190 131 90 43 28 25 21 73 138 150 169 176 183 189 190 193 196 198 199 197 193 193 192 189 191 196 199 203 207 208 210 212 211 207 203 202 196 186 173 152 134 96 16 17 117 135 78 100 194 106 95 62 28 19 18 17 76 133 145 160 170 179 182 186 191 191 193 197 196 196 197 200 207 211 212 215 217 217 216 214 212 206 201 195 187 170 153 137 90 21 13 70 146 117 78 46 102 64 100 93 43 26 25 18 14 72 134 146 155 168 175 180 183 183 189 195 197 200 204 211 216 218 218 218 217 218 217 214 210 203 196 187 166 145 127 75 19 29 50 112 144 84 54 23 0 174 72 93 92 53 19 26 17 9 55 127 152 154 164 172 178 183 187 193 198 202 205 209 213 215 215 215 214 214 213 211 205 195 192 167 132 100 41 10 42 51 74 133 105 46 37 14 26 164 151 82 77 77 53 20 11 11 2 26 93 137 149 155 163 174 182 190 199 202 205 206 209 210 210 209 207 208 211 206 198 188 172 114 55 13 8 56 55 45 126 98 24 41 76 83 79 154 149 156 130 97 91 63 36 19 15 6 7 40 92 129 138 150 166 176 188 196 199 200 203 204 202 200 196 197 198 192 181 166 107 23 1 10 64 46 40 114 135 77 95 143 142 115 83\",\n          \"1 11 10 7 6 0 4 9 6 5 11 12 14 18 24 28 30 45 52 60 60 57 65 70 70 68 77 71 68 59 48 44 44 37 24 16 20 14 14 18 15 15 12 18 16 14 10 9 4 7 9 7 7 2 9 13 11 8 11 16 24 34 41 40 51 60 56 59 66 68 67 75 78 81 86 80 77 75 58 49 50 44 36 31 26 20 22 20 16 12 14 18 16 12 9 10 6 8 10 13 12 11 9 10 8 11 16 21 30 39 47 55 62 68 71 75 72 81 82 91 96 90 88 92 83 83 73 63 55 46 45 42 36 23 25 16 12 8 15 19 14 15 12 17 4 8 11 9 10 6 8 10 11 13 18 28 38 44 49 61 68 70 73 76 79 78 82 85 89 90 87 92 89 76 68 67 59 58 50 51 42 35 31 21 15 18 13 17 14 15 10 19 2 3 5 5 7 8 10 13 16 17 21 32 39 45 53 64 67 69 74 78 81 83 88 87 88 92 93 95 92 76 70 68 60 53 53 55 42 41 43 28 16 14 11 10 13 11 11 13 0 1 3 2 3 7 10 12 14 18 21 34 41 50 58 63 68 78 85 86 85 84 88 90 89 92 96 90 83 83 74 72 71 62 58 56 52 48 43 28 14 12 9 9 14 15 15 14 1 1 3 2 4 7 10 12 16 20 29 40 47 51 56 61 74 81 85 90 89 91 92 90 95 100 95 89 78 79 78 79 77 75 75 69 60 58 51 36 17 12 11 12 14 12 9 9 3 5 2 5 5 10 13 16 20 31 41 40 44 51 57 61 74 82 90 88 89 89 92 93 94 101 98 90 86 87 87 83 79 78 75 74 65 67 63 39 28 16 10 8 10 10 7 9 2 4 5 5 8 11 13 18 28 39 47 45 46 48 54 60 66 80 91 94 89 86 91 96 97 102 104 90 86 93 89 84 83 79 75 76 76 66 64 55 48 27 10 8 12 11 13 17 1 2 3 3 9 11 13 25 37 46 54 53 50 50 55 60 65 76 87 92 94 97 97 92 95 96 97 92 95 99 86 83 84 79 76 74 76 74 74 69 60 35 9 8 10 13 17 16 0 3 2 5 8 12 18 33 36 41 48 51 53 55 56 62 70 72 86 91 93 92 98 88 92 103 101 98 97 113 85 78 94 88 79 81 80 79 73 68 67 49 10 5 11 12 16 17 0 3 3 5 9 19 30 36 38 43 48 51 53 57 61 60 75 78 83 85 78 71 86 75 81 78 94 98 99 113 112 91 117 113 88 72 78 78 75 67 68 63 15 7 10 15 19 22 0 3 3 1 10 23 34 40 44 50 54 52 55 67 69 59 74 76 62 70 71 74 93 79 69 53 52 76 83 82 86 80 87 74 51 52 64 61 62 70 71 67 24 7 12 20 20 22 1 1 1 2 10 23 32 39 48 53 67 75 69 72 66 59 58 52 63 72 75 73 89 82 74 52 55 48 43 48 41 43 45 40 46 55 61 59 60 67 72 68 35 13 22 23 24 31 1 2 1 1 12 27 36 41 48 49 50 57 50 37 39 37 34 35 47 58 70 69 83 85 71 53 44 35 34 27 38 47 49 58 70 72 70 74 73 71 75 73 50 24 28 18 38 48 2 6 5 1 14 29 35 33 37 30 20 19 20 21 20 21 22 27 30 46 62 67 80 82 71 65 51 32 23 27 40 45 58 75 73 74 74 70 69 69 70 75 65 37 31 22 58 66 4 9 4 1 19 29 27 29 26 23 26 26 22 23 19 15 13 24 40 52 58 61 76 84 74 64 63 52 49 44 28 39 41 47 50 43 44 57 65 63 68 77 71 49 60 58 70 98 2 12 4 1 19 30 35 38 37 37 38 42 42 36 32 33 40 53 60 54 48 54 74 87 79 71 69 62 53 35 12 11 16 26 34 37 40 28 41 56 65 78 78 63 98 103 78 104 0 6 7 2 19 37 39 39 38 40 38 38 35 28 25 26 28 44 58 55 47 49 79 93 86 81 77 57 48 40 40 20 0 0 9 29 23 37 32 52 74 79 79 73 97 101 76 84 0 4 14 3 21 39 38 35 32 25 16 9 6 15 9 6 12 22 42 50 47 44 85 105 91 88 84 63 54 48 53 59 36 52 63 73 59 47 61 78 86 88 80 77 86 90 65 56 0 2 3 4 23 37 28 28 21 12 7 12 4 4 4 13 14 17 33 40 49 49 98 118 100 90 94 80 58 55 52 56 71 92 83 67 59 59 70 85 92 92 82 79 84 93 65 81 11 2 8 13 27 40 29 19 10 10 17 35 31 33 50 62 46 28 27 47 60 56 112 132 110 96 108 102 76 60 55 55 58 59 58 58 62 67 74 86 95 89 82 79 83 86 74 100 21 3 10 20 33 47 44 37 24 27 43 47 48 57 59 55 58 62 50 61 69 75 118 129 108 101 108 106 95 77 73 80 78 84 90 94 98 94 88 97 101 90 80 79 82 80 70 77 10 9 7 25 38 48 50 48 41 34 36 41 44 45 54 63 68 74 69 73 73 87 117 119 107 103 101 100 102 96 88 83 86 92 99 104 100 101 97 101 101 92 81 79 81 84 75 70 36 18 9 24 38 48 57 52 45 46 48 52 54 61 75 84 84 86 80 77 77 84 104 112 106 104 106 103 103 108 112 108 103 104 106 105 99 104 102 99 98 93 81 75 82 82 90 96 79 38 20 27 40 45 56 55 49 57 56 54 58 64 71 80 86 90 78 70 72 78 96 103 99 97 104 103 105 110 115 121 119 118 123 117 116 110 104 97 95 92 84 82 84 76 93 123 40 27 31 31 40 44 52 56 53 60 64 61 61 70 79 91 94 88 72 57 64 78 92 95 96 89 88 91 85 95 106 118 131 127 130 128 126 125 115 104 96 91 83 82 81 98 112 118 65 59 29 37 40 44 49 51 53 60 64 65 76 81 89 98 94 77 54 51 67 96 119 114 102 93 89 80 77 72 82 106 125 130 134 135 134 126 115 111 95 90 83 83 80 116 143 133 127 124 60 26 42 44 47 50 54 64 74 80 87 85 89 92 89 55 42 51 71 123 147 131 142 129 85 84 89 82 68 77 102 118 131 135 132 126 122 110 96 89 82 84 84 124 144 139 122 125 121 76 38 44 48 50 58 70 80 84 85 87 86 87 71 46 62 62 68 98 110 134 152 128 87 110 113 93 72 62 72 93 106 114 120 117 114 107 100 88 81 84 92 128 134 135 124 124 130 118 40 46 49 51 63 77 83 82 85 86 82 79 49 47 69 66 55 69 87 99 96 86 75 54 65 86 68 75 67 71 84 93 103 108 103 103 96 88 82 81 105 189 179 176 122 123 123 123 54 43 49 51 61 70 76 77 80 81 78 59 37 51 46 13 26 52 70 83 79 63 17 0 10 39 71 105 92 68 80 86 90 94 102 94 89 88 86 79 135 226 216 209 122 122 122 128 67 41 51 51 56 61 67 73 75 77 64 40 51 50 30 17 8 16 51 63 62 49 61 64 56 64 110 120 110 85 66 79 81 85 92 86 84 92 90 80 161 220 213 207 123 121 122 127 92 42 53 49 50 56 62 68 73 68 44 43 62 68 36 27 27 19 17 35 54 85 105 105 112 120 124 122 115 106 75 69 76 78 81 82 87 92 86 91 190 203 215 222 124 123 122 124 117 50 51 50 49 50 56 63 67 56 41 54 71 76 70 49 41 42 44 65 83 102 114 120 120 117 118 115 111 108 97 65 65 69 74 79 87 90 83 113 180 174 221 237 121 121 119 115 127 78 45 57 52 48 52 56 55 49 47 57 69 72 73 73 74 83 98 110 100 103 120 121 118 116 112 115 108 101 97 79 61 60 67 77 84 86 86 131 176 211 225 219 111 112 124 142 134 98 48 55 57 52 49 46 50 50 49 52 65 75 79 87 91 100 105 110 102 102 115 119 114 110 108 110 106 94 85 80 68 64 67 76 83 86 95 120 197 203 200 197 113 147 183 179 127 99 65 48 54 57 47 42 47 52 52 53 65 77 86 87 87 94 109 118 108 104 117 122 114 112 105 102 101 91 79 75 73 73 73 77 80 89 96 124 157 189 191 199 178 194 185 163 116 85 70 53 49 51 47 44 46 52 47 52 60 68 80 88 86 83 97 108 115 109 101 96 94 89 85 81 79 74 70 71 75 80 81 78 82 96 86 104 133 178 194 194 193 180 161 141 109 70 57 62 50 50 47 44 46 50 40 46 51 52 56 63 67 68 71 64 81 84 81 84 77 73 68 57 47 48 60 68 75 84 83 80 85 94 76 80 104 144 160 102 165 148 137 134 114 81 77 73 59 50 50 46 44 48 37 34 33 40 48 45 51 57 60 59 59 77 78 68 66 66 68 84 86 68 65 67 74 80 83 82 90 82 63 73 80 98 50 65 131 142 150 153 136 102 86 66 52 53 51 51 46 43 36 34 42 47 48 58 43 38 38 45 34 52 67 85 97 98 94 93 88 83 82 73 74 75 81 80 90 62 53 63 85 87 71 202 163 155 151 155 139 100 59 46 68 76 54 53 48 43 41 41 51 62 64 98 108 113 115 112 97 110 121 156 138 103 86 83 80 90 83 76 74 73 74 83 81 48 48 55 108 82 140 209 180 160 114 94 107 94 97 121 113 84 62 57 52 46 43 46 47 57 56 62 80 97 114 132 127 116 113 103 89 90 88 82 82 87 81 76 74 74 78 84 74 32 26 45 49 34 140 177 170 148 63 97 154 176 171 139 101 70 53 60 52 47 46 49 49 49 54 65 66 73 85 91 94 87 84 77 83 89 75 81 84 82 79 76 75 75 76 81 71 43 20 12 8 19 113 176 131 84 134 191 194 196 181 138 102 62 34 52 58 51 48 49 51 49 48 52 58 56 55 55 54 50 52 58 66 71 78 83 83 82 81 78 76 72 79 76 66 51 46 28 9 4 59 170 93 133 192 198 198 190 184 151 97 43 28 38 55 58 51 50 50 49 48 45 39 41 43 51 58 66 74 78 83 88 89 85 81 81 83 78 68 69 78 72 65 57 52 37 9 9 33 145 134 188 202 203 201 194 188 156 86 28 22 39 34 57 55 53 52 52 50 53 57 64 73 84 87 90 90 93 92 89 87 84 80 82 79 66 60 77 76 73 63 62 60 46 13 15 18 122\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "#class for data-preprocessing\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(self.dataframe.iloc[idx]['pixels'].split(), dtype=np.uint8).reshape(48, 48)\n",
        "        image = Image.fromarray(image)\n",
        "        label = int(self.dataframe.iloc[idx]['emotion'])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),                # Resize the image to 224x224 as ViT requires this input size\n",
        "    transforms.RandomHorizontalFlip(p=0.5),       # Randomly flip the image horizontally\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Randomly crop and resize\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel image\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Slight color jitter\n",
        "    transforms.ToTensor(),                        # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
        "])\n",
        "\n",
        "# The rotation transformation didn't improve the accuracy rather it decreased so\n",
        "# Create dataset and dataloaders\n",
        "train_dataset = CustomDataset(dataframe=train_df, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T08:16:24.360478Z",
          "iopub.execute_input": "2024-09-16T08:16:24.360995Z",
          "iopub.status.idle": "2024-09-16T08:16:28.95073Z",
          "shell.execute_reply.started": "2024-09-16T08:16:24.360943Z",
          "shell.execute_reply": "2024-09-16T08:16:28.949619Z"
        },
        "trusted": true,
        "id": "uGChVmII6Amx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with train and val"
      ],
      "metadata": {
        "id": "n8qfce-v6Amy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(self.dataframe.iloc[idx]['pixels'].split(), dtype=np.uint8).reshape(48, 48)\n",
        "        image = Image.fromarray(image)\n",
        "        label = int(self.dataframe.iloc[idx]['emotion'])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),                # Resize the image to 224x224 as ViT requires this input size\n",
        "    transforms.RandomHorizontalFlip(p=0.5),       # Randomly flip the image horizontally\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Randomly crop and resize\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel image\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Slight color jitter\n",
        "    transforms.ToTensor(),                        # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
        "])\n",
        "\n",
        "# Creating dataset\n",
        "full_dataset = CustomDataset(dataframe=train_df, transform=transform)\n",
        "\n",
        "\n",
        "dataset_size = len(full_dataset)\n",
        "train_size = int(0.9 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Now you have train_loader and val_loader ready for training and validation\n",
        "print(\"done\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T08:16:30.48053Z",
          "iopub.execute_input": "2024-09-16T08:16:30.4811Z",
          "iopub.status.idle": "2024-09-16T08:16:30.519828Z",
          "shell.execute_reply.started": "2024-09-16T08:16:30.481058Z",
          "shell.execute_reply": "2024-09-16T08:16:30.518624Z"
        },
        "trusted": true,
        "id": "7YmwmP8O6Amz",
        "outputId": "c7b16933-038d-4fe0-dca0-1e0acdd8b900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load a pretrained ViT model\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "\n",
        "# Modify the final layer for your number of classes\n",
        "num_classes = 7  # Number of emotion classes\n",
        "model.head = nn.Linear(model.head.in_features, num_classes)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T08:16:33.616151Z",
          "iopub.execute_input": "2024-09-16T08:16:33.616603Z",
          "iopub.status.idle": "2024-09-16T08:16:40.099788Z",
          "shell.execute_reply.started": "2024-09-16T08:16:33.616562Z",
          "shell.execute_reply": "2024-09-16T08:16:40.098568Z"
        },
        "trusted": true,
        "id": "S_G120Dp6Am0",
        "outputId": "2ae2f926-82f9-44e4-94f0-246d6e86ada5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "6a0551371bba4bf5b099326a46fa8059",
            "1c813c30e04f4ca6ba7a4a656e56a5b7",
            "efc0b1a765eb48ec92be78e140ec21bb",
            "83aa103eba9645daafdcef0b54223e89",
            "f4340ef21cd04664965add3d0ec3aa45",
            "f379cb74a94046f496f0de2d03ee933f",
            "c262e63427c34f07a19ad37c686a184e",
            "52820c343d3d44ccacbbed70e7d5f53b",
            "1a0352abbff747829537cab70880be9f",
            "1ff6ca98e665413994e485cb814a199a",
            "ec403adbe96346a4891d6b5717465918"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a0551371bba4bf5b099326a46fa8059"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "freezing the layers gave bad accuracy"
      ],
      "metadata": {
        "id": "sdgN6jai6Am1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = nn.DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "# Class counts from dataset\n",
        "class_counts = torch.tensor([1142, 780, 741, 661, 643, 467, 66], dtype=torch.float)\n",
        "total_samples = class_counts.sum()\n",
        "\n",
        "# Calculating class weights inversely proportional to frequency\n",
        "class_weights = total_samples / (len(class_counts) * class_counts)\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
        "    best_val_acc = 0.0  # Tracking the best validation accuracy\n",
        "    best_model_path = 'best_model.pth'\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        print(f\"Training Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = 100 * correct_val / total_val\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\\n\")\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save the model if the validation accuracy improves\n",
        "        if val_accuracy > best_val_acc:\n",
        "            best_val_acc = val_accuracy\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Saved best model with validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "    # Load the best model after training\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    print(f\"Loaded best model from epoch with validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "# Call the function to start training and evaluation\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T08:16:49.627379Z",
          "iopub.execute_input": "2024-09-16T08:16:49.627847Z"
        },
        "trusted": true,
        "id": "l7jM5XZF6Am2",
        "outputId": "1084510c-6eff-428b-9ce3-0b39ae418d8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Training: 100%|██████████| 141/141 [02:55<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.9974, Accuracy: 31.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8175, Accuracy: 39.40%\n",
            "\n",
            "Saved best model with validation accuracy: 39.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Training: 100%|██████████| 141/141 [02:53<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7204, Accuracy: 47.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8062, Accuracy: 38.40%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 - Training: 100%|██████████| 141/141 [02:53<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6266, Accuracy: 53.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7387, Accuracy: 49.20%\n",
            "\n",
            "Saved best model with validation accuracy: 49.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 - Training: 100%|██████████| 141/141 [02:54<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5117, Accuracy: 60.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7419, Accuracy: 51.80%\n",
            "\n",
            "Saved best model with validation accuracy: 51.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 - Training: 100%|██████████| 141/141 [02:52<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4368, Accuracy: 66.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8338, Accuracy: 56.20%\n",
            "\n",
            "Saved best model with validation accuracy: 56.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 - Training: 100%|██████████| 141/141 [02:53<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3733, Accuracy: 71.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8029, Accuracy: 59.00%\n",
            "\n",
            "Saved best model with validation accuracy: 59.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 - Training: 100%|██████████| 141/141 [02:53<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2745, Accuracy: 78.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8408, Accuracy: 58.00%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 - Training: 100%|██████████| 141/141 [02:53<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1841, Accuracy: 84.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9161, Accuracy: 63.00%\n",
            "\n",
            "Saved best model with validation accuracy: 63.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10 - Training: 100%|██████████| 141/141 [02:53<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1541, Accuracy: 86.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1297, Accuracy: 62.20%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10 - Training: 100%|██████████| 141/141 [02:53<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.1380, Accuracy: 88.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10 - Validation: 100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0861, Accuracy: 64.20%\n",
            "\n",
            "Saved best model with validation accuracy: 64.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-929a3a48d352>:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best model from epoch with validation accuracy: 64.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "DdzNXWYI6Am2",
        "outputId": "c98119f5-5f2a-4457-bc7d-08db6bfcdde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-97ca0473330f>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wTCpb-Fg6Am2",
        "outputId": "bd1c751a-e825-40cc-93cf-8f423dbf6f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): VisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (patch_drop): Identity()\n",
              "    (norm_pre): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (4): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (5): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (6): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (7): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (8): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (9): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (10): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (11): Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (fc_norm): Identity()\n",
              "    (head_drop): Dropout(p=0.0, inplace=False)\n",
              "    (head): Linear(in_features=768, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "T8ud7Tcm6Am3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert the 'pixels' column to a NumPy array and reshape it\n",
        "        image_array = np.array(self.dataframe.iloc[idx]['pixels'].split(), dtype=np.uint8).reshape(48, 48)\n",
        "        image = Image.fromarray(image_array)\n",
        "        image_id = self.dataframe.iloc[idx]['id']  # Get the image ID\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_id\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resizing image to 224x224\n",
        "    transforms.Grayscale(num_output_channels=3),  # Converting grayscale to 3-channel\n",
        "    transforms.ToTensor(),  # Converting image to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizing using ImageNet stats\n",
        "])\n",
        "\n",
        "# Create dataset and dataloaders\n",
        "test_dataset = CustomDataset(dataframe=test_df, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"done\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "vrvPjH-b6Am3",
        "outputId": "c4c0f1d9-cf8d-43f9-a5fb-46a59bfe74bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Initialize the model and load the trained weights\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "num_classes = 7  # Number of emotion classes\n",
        "model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "model = nn.DataParallel(model)  # Wrap the model for multi-GPU\n",
        "model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n",
        "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "ids = []\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        print(\"Processing batch\")\n",
        "        images, batch_ids = batch\n",
        "\n",
        "        # Move images and batch IDs to the appropriate device\n",
        "        images = images.to(device)\n",
        "        batch_ids = batch_ids.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
        "\n",
        "        # Collect predictions and IDs\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        ids.extend(batch_ids.cpu().numpy())\n",
        "\n",
        "# Create a DataFrame with IDs and predictions\n",
        "results_df = pd.DataFrame({\n",
        "    'id': ids,\n",
        "    'predictions': predictions\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv('predictions_vit_class_based_weights_1_without_rotation.csv', index=False)\n",
        "print(\"Prediction done\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "e_hqjfBD6Am3",
        "outputId": "468bc6ea-e8c8-4a4c-aebb-9af6ba1096da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-7421b59381f9>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Processing batch\n",
            "Prediction done\n"
          ]
        }
      ]
    }
  ]
}